# data-pipeline-for-music-recommendation

실시간 가상 음악 스트리밍 이벤트 제너레이터로부터 발생 이벤트를 처리하는 파이프라인 구축 프로젝트 

Building a pipeline to process event data generated by a virtual music streaming site for music recommendation.

---

## Project Description

This project involves building a comprehensive data pipeline to reliably collect event logs generated by a virtual music streaming platform, preprocess and store the data, and provide the capability to visualize the stored data through a dashboard.



### System Architecture
<img width="738" alt="medalion" src="https://github.com/dharana77/data-pipeline-for-music-recommendation/assets/77390758/cdca8102-a94a-4fb1-90b1-539d2ce693c8">

1. **Data Collection (Orange):**

   - Fluentd collects four types of event data.
   - The collected data is sent to the Data Lake.

2. **Data Processing in Silver Phase (Blue):**

   - In this phase, raw data (Bronze Phase) is filtered and processed.
   - The processed data is stored in the Data Lake in Parquet format.

3. **Data Processing in Gold Phase (Yellow):**

   - Aggregations are performed on the Fact Table.
   - Fact Table is merged with relevant Dimension Table for advanced analysis.

4. **Data Loading and Visualization (Black):**

   - The final processed data is ingested from the Data Lake to Druid.
   - Data is visualized by connecting Druid with Superset.

### Data

[Eventsim](https://github.com/Interana/eventsim) is a program designed to generate event data that simulates page requests for a fictional music website. The resulting data closely resembles real user interactions but is entirely synthetic. The Docker image for Eventsim is sourced from [viirya's fork](https://github.com/viirya/eventsim), which was originally used in the Streamify project [Streamify](https://github.com/ankurchavda/streamify).

Eventsim leverages song data from the [Million Songs Dataset](http://millionsongdataset.com) to generate these events. I used a subset of 10,000 songs from the Million Songs Dataset as the basis for simulating user interactions.

### Tools & Technologies

- Cloud - [**AWS**](https://console.aws.amazon.com/console/home?nc2=h_ct&src=header-signin)
- Containerization - [**Docker**](https://www.docker.com), [**Kubernetes**](https://kubernetes.io/)
- Data Collection - [**Fluentd**](https://www.fluentd.org/)
- Data Processing - [**Spark**](https://spark.apache.org/)
- Orchestration - [**Airflow**](https://airflow.apache.org)
- Data Lake - [**S3 Buckeet**]()
- Data Serving - [**Druid**](https://druid.apache.org/)
- Data Visualization - [**SuperSet**](https://superset.apache.org/)
- Language - [**Python**](https://www.python.org)

### Final Results



---

## Blog

1. Project Description [Link]()
2. Data Extraction [Link]()
3. Data Transformation [Link]()
4. Data Load [Link]()
